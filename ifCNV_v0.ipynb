{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "###########################################\n",
    "#               FUNCTIONS                 #\n",
    "###########################################\n",
    "\n",
    "\n",
    "def clean_reference(ref,outliers):\n",
    "    for i in outliers:\n",
    "        ref = ref.drop(labels=i,axis=1)\n",
    "\n",
    "    return ref\n",
    "\n",
    "def norm_ref(ref):\n",
    "    med = ref.median(axis=0)\n",
    "    norm_ref = ref/med\n",
    "    return norm_ref, med\n",
    "\n",
    "def create_synthetic(norm_ref,med,N):\n",
    "    synt = pd.DataFrame(index=norm_ref.index,columns=range(N))\n",
    "    for j in range(N):\n",
    "        for i in norm_ref.index:\n",
    "            synt[j][i] = np.random.choice(norm_ref.loc[norm_ref.index==i].values.flatten())\n",
    "\n",
    "        synt[j] = synt[j] * np.random.choice(med)\n",
    "    synt.columns = [\"sample_\" + str(i) for i in range(synt.shape[1])]\n",
    "    return synt\n",
    "\n",
    "def add_features(synt,sample,gene,factor,exon=None):\n",
    "    if exon is None:\n",
    "        pattern = gene\n",
    "        tmp = [str(synt.index[i]).split(\"_\")[0] for i in range(synt.shape[0])]\n",
    "        synt.loc[[tmp[i]==pattern for i in range(len(tmp))],sample] = synt.loc[[tmp[i]==pattern for i in range(len(tmp))]][sample] * factor\n",
    "        \n",
    "    if exon is not None:\n",
    "        pattern = gene + \"_\" + exon\n",
    "        tmp = [str(synt.index[i]).split(\"_\")[0] + \"_\" + str(synt.index[i]).split(\"_\")[1] for i in range(synt.shape[0])] \n",
    "        synt.loc[[tmp[i]==pattern for i in range(len(tmp))],sample] = synt.loc[[tmp[i]==pattern for i in range(len(tmp))]][sample] * factor\n",
    "    \n",
    "    res = synt\n",
    "    return res\n",
    "\n",
    "\n",
    "def openJson(path,n):\n",
    "    \"\"\"\n",
    "    Opens json files in path to create a reads matrix\n",
    "    \"\"\"\n",
    "    tmp = os.listdir(path)\n",
    "    tmp = np.array(tmp)[np.array([bool(re.findall(\"depths.json$\",tmp[i])) for i in range(len(tmp))])]\n",
    "    reads = np.zeros((n,len(tmp)))\n",
    "    amplicons = [\"\" for x in range(n)]\n",
    "    q=0\n",
    "    for p in tmp:\n",
    "        with open(path+p) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            for i in range(n):\n",
    "                amplicons[i] = data[i]['name']\n",
    "                for j in data[i]['depths']:\n",
    "                    reads[i,q] = int(data[i]['depths'][j]['min'])\n",
    "        q=q+1\n",
    "    reads = pd.DataFrame(data = reads,index=amplicons)\n",
    "    reads.columns = [i.split('_')[0]+'_'+i.split('_')[1] for i in tmp]\n",
    "    return reads\n",
    "\n",
    "def sumLibraries(reads):\n",
    "    samples = np.unique([i.split('_')[0] for i in reads.columns])\n",
    "    reads_f = np.zeros((reads.shape[0],len(samples)))\n",
    "    q=0\n",
    "    for i in samples:\n",
    "        sub = reads.filter(regex=\"^\"+i)\n",
    "        reads_f[:,q] = sub.sum(axis=1)\n",
    "        q=q+1\n",
    "    reads_f = pd.DataFrame(data = reads_f,index=reads.index)\n",
    "    reads_f.columns = list(samples)\n",
    "    return(reads_f)\n",
    "\n",
    "def correctIndex(reads,correspondance):\n",
    "    l = [\"\" for x in range(len(reads.index))]\n",
    "    q=0\n",
    "    for i in reads.index:\n",
    "        l[q] = i[(len(i)-9):len(i)]\n",
    "        q=q+1\n",
    "    final = reads[[correspondance[\"amplicon\"][0] in l[x] for x in range(len(l))]]\n",
    "    for i in correspondance[\"amplicon\"]:\n",
    "        if i!=correspondance[\"amplicon\"][0]:\n",
    "            final = pd.concat([final,reads[[i in l[x] for x in range(len(l))]]])\n",
    "    final.index = correspondance[\"gene_exon\"] + \"_\" + correspondance[\"amplicon\"]\n",
    "    return final\n",
    "\n",
    "\n",
    "def filterReads(reads,N,output_path):\n",
    "    reads = reads.loc[:,reads.sum(axis=0)>N]\n",
    "    reads = reads.filter(regex=\"^(?!MSI)\",axis=0)\n",
    "    reads = reads.filter(regex=\"^(?!TN)\")\n",
    "    reads = reads.filter(regex=\"^(?!TP)\")\n",
    "    reads = reads.filter(regex=\"^(?!HD)\")\n",
    "    reads = reads.filter(regex=\"^(?!H2)\")\n",
    "    reads.to_csv(output_path, sep=\"\\t\",index=True)\n",
    "    return(reads)\n",
    "\n",
    "\n",
    "def normalizeReads(reads,output_path=None,save=False):\n",
    "    reads_norm=reads/reads.median(axis=0)\n",
    "    reads = np.log(reads+1)\n",
    "    if save==True:\n",
    "        reads_norm.to_csv(output_path, sep=\"\\t\",index=True)\n",
    "    return(reads_norm)\n",
    "\n",
    "\n",
    "def aberrantSamples(reads,conta='auto'):\n",
    "    #reads = reads/np.sum(reads)\n",
    "    \n",
    "    tmp = np.percentile(reads, 99, axis = 0)/np.mean(reads, axis = 0)\n",
    "    random_data = np.array(tmp).reshape(-1,1)\n",
    "    clf = IsolationForest(contamination=conta).fit(random_data)\n",
    "    preds = clf.predict(random_data)\n",
    "    res_amp = np.array(reads.columns)[preds==-1]\n",
    "    \n",
    "    tmp = np.percentile(reads, 1, axis = 0)/np.mean(reads, axis = 0)\n",
    "    random_data = np.array(tmp).reshape(-1,1)\n",
    "    clf = IsolationForest(contamination=conta).fit(random_data)\n",
    "    preds = clf.predict(random_data)\n",
    "    res_del = np.array(reads.columns)[preds==-1]\n",
    "    \n",
    "    res = np.unique(np.concatenate((res_amp,res_del)))\n",
    "    norm = reads.columns[~np.in1d(reads.columns,res)]\n",
    "    \n",
    "    return(res, norm)\n",
    "\n",
    "\n",
    "def aberrantSamples2(reads):\n",
    "    read = reads.astype(\"float\")\n",
    "    tmp = np.percentile(reads, 5, axis = 0)/np.mean(reads, axis = 0)\n",
    "    random_data = np.array(tmp).reshape(-1,1)\n",
    "\n",
    "    clf = IsolationForest(contamination=0.1).fit(random_data)\n",
    "    preds = clf.predict(random_data)\n",
    "    res = np.array(reads.columns)[preds==-1]\n",
    "    return(res)\n",
    "\n",
    "\n",
    "def aberrantAmplicons(reads_norm,abSamples):\n",
    "    for name in res:\n",
    "        random_data = np.array(reads_norm[name]).reshape(-1,1)\n",
    "        clf = IsolationForest(contamination=0.001).fit(np.array(np.mean(reads_norm, axis = 1)).reshape(-1,1))\n",
    "        preds = clf.predict(random_data)\n",
    "        print(name)\n",
    "        print(np.array(reads_norm.index)[preds==-1])\n",
    "\n",
    "def aberrantAmpliconsPerSample(name,reads_norm,conta='auto',verbose=False):\n",
    "    random_data = np.array(reads_norm[name]).reshape(-1,1)\n",
    "    clf = IsolationForest(contamination=conta).fit(np.array(np.mean(reads_norm, axis = 1)).reshape(-1,1))\n",
    "    preds = clf.predict(random_data)\n",
    "    if verbose:\n",
    "        print(name)\n",
    "        print(np.array(reads_norm.index)[preds==-1])\n",
    "    return(np.array(reads_norm.index)[preds==-1])\n",
    "\n",
    "\n",
    "def aberrantAmpliconsPerSample2(name,reads,abSamples,verbose=False):\n",
    "    ab = [i in abSamples for i in reads.columns]\n",
    "    normalReads = reads[np.delete(reads.columns,ab)]\n",
    "    med = np.percentile(normalReads, 99, axis = 1)\n",
    "    reads = (reads.T/med).T\n",
    "    random_data = np.array(reads[name]).reshape(-1,1)\n",
    "    clf = IsolationForest(contamination=0.05).fit(np.array(np.median(reads, axis = 1)).reshape(-1,1))\n",
    "    preds = clf.predict(random_data)\n",
    "    if verbose:\n",
    "        print(name)\n",
    "        print(np.array(reads.index)[preds==-1])\n",
    "    return(np.array(reads.index)[preds==-1])\n",
    "\n",
    "\n",
    "\n",
    "def percentagePerExon(amplified,reads,verbose=False):\n",
    "    genes = [i.split('_')[0] for i in reads.index]\n",
    "    exons = [i.split('_')[1] for i in reads.index]\n",
    "    g_e = [genes[i]+'_'+exons[i] for i in range(len(genes))]\n",
    "    n_ge = np.array([g_e.count(i) for i in np.unique(g_e)])\n",
    "    ag = [i.split('_')[0] for i in amplified]\n",
    "    ae = [i.split('_')[1] for i in amplified]\n",
    "    age = [ag[i]+'_'+ae[i] for i in range(len(amplified))]\n",
    "    f = pd.DataFrame(index=np.unique(age),columns=[\"percentage\"])\n",
    "    f = f.fillna(0)\n",
    "    for i in range(len(np.unique(age))):\n",
    "        f['percentage'][i] = 100*float(age.count(''.join(np.unique(age)[i]))/n_ge[np.unique(g_e)==''.join(np.unique(age)[i])])\n",
    "        if verbose:\n",
    "            if f['percentage'][i]>50:\n",
    "                print(np.unique(age)[i] + \": \" + str(round(f['percentage'][i]))+'%'+' des amplicons de l\\'exon sont aberrants')\n",
    "    return(f)\n",
    "\n",
    "def percentagePerGene(amplified,reads,verbose=False):\n",
    "    genes = [i.split('_')[0] for i in reads.index]\n",
    "    ag = [i.split('_')[0] for i in amplified]\n",
    "    n_g = np.array([genes.count(i) for i in np.unique(genes)])\n",
    "    f = pd.DataFrame(index=np.unique(ag),columns=[\"percentage\"])\n",
    "    f = f.fillna(0)\n",
    "    for i in range(len(np.unique(ag))):\n",
    "        f['percentage'][i] = 100*float(ag.count(''.join(np.unique(ag)[i]))/n_g[np.unique(genes)==''.join(np.unique(ag)[i])])\n",
    "        if verbose:\n",
    "            if f['percentage'][i]>50:\n",
    "                print(np.unique(ag)[i] + \": \" + str(round(f['percentage'][i]))+'%'+' des amplicons du gene sont aberrants')\n",
    "    return(f)\n",
    "\n",
    "def amplifEvalGene(reads,abSamples,gene,sample):\n",
    "    reads_m = reads/reads.median(axis=0)\n",
    "    sub = reads_m\n",
    "    for i in abSamples:\n",
    "        sub = sub.drop(labels=i,axis=1)\n",
    "    reads_m = reads_m.filter(regex=\"^\"+gene,axis=0)\n",
    "    reads_m = reads_m[sample]   \n",
    "    val = np.mean(reads_m)/np.mean(sub.mean())\n",
    "    if val==np.inf:\n",
    "        val = 100\n",
    "    return val\n",
    "\n",
    "def scoreAmplif(k,n,N):\n",
    "    p = n/N\n",
    "    x = np.log(1/((p**k)*(1-p)**(n-k)))*(k/n)\n",
    "    # score = 1/(1+np.exp(-x))\n",
    "    score = x/390 + 190/390\n",
    "    \n",
    "    return x\n",
    "\n",
    "def aberrantAmpliconsFinal(reads, reads_norm, abSamples,abSamples2,run,threshold):\n",
    "    f = pd.DataFrame(columns=[\"run\",\"name\",\"gene\",\"amplif\",\"score\"])\n",
    "        \n",
    "    q=0 \n",
    "    for name in abSamples2:\n",
    "        #abAmp = aberrantAmpliconsPerSample2(name,reads_norm,abSamples,verbose=False)\n",
    "        abAmp = aberrantAmpliconsPerSample(name,reads_norm,verbose=False)\n",
    "        if abAmp.shape!=(0,):\n",
    "            genes = np.unique([i.split('_')[0] for i in abAmp])\n",
    "            for gene in genes:\n",
    "                r = re.compile(gene)\n",
    "                abEx = list(filter(r.match, abAmp))\n",
    "                exons1 = [i.split('_')[0]+\"_\"+i.split('_')[1] for i in abEx]\n",
    "                tmp = reads.filter(regex=\"^\"+gene,axis=0)\n",
    "                exons2 = [i.split('_')[0]+\"_\"+i.split('_')[1] for i in tmp.index]\n",
    "                \n",
    "                score = scoreAmplif(len(abEx),tmp.shape[0],reads.shape[0])\n",
    "                \n",
    "                amplif = amplifEvalGene(reads, abSamples, gene, name)\n",
    "\n",
    "                if score>threshold:\n",
    "                    if amplif>1:\n",
    "                        f.loc[q] = [run,name,gene,amplif,score]\n",
    "                        q=q+1\n",
    "                    #if amplif<1:\n",
    "                    #    f.loc[q] = [run,name,gene,amplif,score]\n",
    "                    #    q=q+1\n",
    "\n",
    "    return(f)\n",
    "\n",
    "\n",
    "def aberrantAmpliconsFinal2(reads, reads_norm, abSamples,abSamples2,run,threshold):\n",
    "    f = pd.DataFrame(columns=[\"run\",\"name\",\"gene\",\"amplif\",\"score\"])\n",
    "        \n",
    "    q=0 \n",
    "    for name in abSamples2:\n",
    "        #abAmp = aberrantAmpliconsPerSample2(name,reads_norm,abSamples,verbose=False)\n",
    "        abAmp = aberrantAmpliconsPerSample(name,reads_norm,verbose=False)\n",
    "        if abAmp.shape!=(0,):\n",
    "            genes = abAmp\n",
    "            for gene in genes:\n",
    "                r = re.compile(gene)\n",
    "                abEx = list(filter(r.match, abAmp))\n",
    "                #print(abEx)\n",
    "                tmp = reads.filter(regex=\"^\"+gene,axis=0)                \n",
    "                score = scoreAmplif(len(abEx),tmp.shape[0],reads.shape[0])\n",
    "                \n",
    "                amplif = amplifEvalGene(reads, abSamples, gene, name)\n",
    "\n",
    "                if score>threshold:\n",
    "                    if amplif>1:\n",
    "                        f.loc[q] = [run,name,gene,amplif,score]\n",
    "                        q=q+1\n",
    "                    #if amplif<1:\n",
    "                    #    f.loc[q] = [run,name,gene,amplif,score]\n",
    "                    #    q=q+1\n",
    "\n",
    "    return(f)\n",
    "\n",
    "\n",
    "\n",
    "def aberrantTargetsCapture(abSamples, normalSamples, reads_norm, conta=None, lower=-0.5, upper=0.5, verbose=True, output_path=False):\n",
    "    if conta == None:\n",
    "        conta = 1/reads_norm.shape[1]\n",
    "    f = pd.DataFrame(columns=[\"name\",\"loc\",\"amp\"])\n",
    "    \n",
    "    norm = np.mean(reads_norm[normalSamples], axis = 1)\n",
    "\n",
    "    q=0\n",
    "    for i in tqdm(reads_norm.columns):            \n",
    "        x = np.array(reads_norm[i]/norm)\n",
    "\n",
    "        if sum(reads_norm[i]/norm>1.5)>1:\n",
    "            #print('duplication: '+i+' '+str(sum(reads_norm[i]/norm>1.4)))\n",
    "            gg=1\n",
    "        if sum(reads_norm[i]/norm<0.6)>1:\n",
    "            #print('deletion:'+i+' '+str(sum(reads_norm[i]/norm<0.6)))\n",
    "            gg=1        \n",
    "        \n",
    "        \n",
    "        if gg==1:\n",
    "            random_data = x.reshape(-1, 1)\n",
    "            clf = IsolationForest(contamination=conta).fit(random_data)\n",
    "            preds = clf.predict(random_data)\n",
    "\n",
    "            det = np.array(reads_norm.index)[preds==-1]\n",
    "\n",
    "            for j in det:\n",
    "                amp = float(x[reads_norm.index==j])\n",
    "                if amp<lower:\n",
    "                    f.loc[q] = [i,j,amp]\n",
    "                    q=q+1\n",
    "                if amp>upper:\n",
    "                    f.loc[q] = [i,j,amp]\n",
    "                    q=q+1\n",
    "        gg=0\n",
    "    \n",
    "    #for i in tqdm(reads_norm.index):\n",
    "#\n",
    "    #    x = np.array(np.log2(reads_norm.loc[i]/float(norm[reads_norm.index==i])))\n",
    "    #    #pd.DataFrame(x).to_csv(\"/Users/admin/Documents/CNV/testttt.tsv\",sep=\"\\t\")\n",
    "    #    random_data = x.reshape(-1, 1)\n",
    "    #    clf = IsolationForest(contamination=conta).fit(random_data)\n",
    "    #    preds = clf.predict(random_data)\n",
    "#\n",
    "    #    det = np.array(final_norm.columns)[preds==-1]\n",
    "    #    ndet = np.array(final_norm.columns)[preds==1]\n",
    "#\n",
    "    #    for j in det:\n",
    "    #        amp = x[final_norm.columns==j]\n",
    "    #        if amp<lower:\n",
    "    #            f.loc[q] = [j,i,amp]\n",
    "    #            q=q+1\n",
    "    #        if amp>upper:\n",
    "    #            f.loc[q] = [j,i,amp]\n",
    "    #            q=q+1\n",
    "                \n",
    "    if verbose:\n",
    "        print(str(f.shape[0])+\" aberrant targets detected in \"+str(len(np.unique(f['name'])))+\" samples\")\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0543e73cf80e4ebd9630164a3e31fc17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=96.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16234 aberrant targets detected in 69 samples\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 2000)\n",
    "output_path = \"/Users/admin/Documents/CNV/\"\n",
    "reads = pd.read_csv(\"/Users/admin/Documents/CNV/final_ICR96_good.txt\",sep=\"\\t\",index_col=0)\n",
    "\n",
    "abSamples, normalSamples = aberrantSamples(reads,conta=0.5)\n",
    "#pd.DataFrame(normalSamples).to_csv(\"/Users/admin/Documents/CNV/normal_samples_icr.tsv\",sep=\"\\t\")\n",
    "\n",
    "final_norm = normalizeReads(reads,output_path,save=False)\n",
    "\n",
    "f = aberrantTargetsCapture(abSamples, normalSamples, final_norm,conta='auto',upper=0,lower=0)\n",
    "\n",
    "f.to_csv(\"/Users/admin/Documents/CNV/icr_res/res_capture_ICR96_test.txt\", sep=\"\\t\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44428eabbc1e4bab93b5fc7d86721f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tp=[]\n",
    "fp=[]\n",
    "tn=[]\n",
    "fn=[]\n",
    "for k in tqdm(range(5,101,5)):\n",
    "    factor = k/10\n",
    "    for p in (range(1000)):\n",
    "        synt = pd.read_csv(\"/Users/admin/Documents/CNV/synthetic_raw_85.tsv\",sep=\"\\t\",index_col=0)\n",
    "        synt = synt[np.random.choice(synt.columns,30,replace=False)]\n",
    "        col = np.random.choice(synt.columns,size=1,replace=False)\n",
    "        normalSamples = synt.columns[~np.in1d(synt.columns,col)]\n",
    "\n",
    "        row = np.random.choice(synt.index,size=1)\n",
    "        #row = pd.read_csv(\"/Users/admin/Documents/CNV/article/figs/data_fig3/rows.tsv\",sep=\"\\t\")\n",
    "        #row = np.array(row)\n",
    "\n",
    "        neg = synt.index[~np.in1d(synt.index,row)]\n",
    "        pos = row\n",
    "\n",
    "        for i in row:\n",
    "            synt.at[i,col[0]] = synt.at[i,col[0]]*factor\n",
    "\n",
    "        synt_norm = normalizeReads(synt)\n",
    "\n",
    "        conta = 'auto'#1/synt_norm.shape[0]\n",
    "\n",
    "        norm = np.mean(synt_norm[normalSamples], axis = 1)\n",
    "\n",
    "        x = np.array(synt_norm[col]/norm[0])     \n",
    "\n",
    "        random_data = x.reshape(-1, 1)\n",
    "        clf = IsolationForest(contamination=conta).fit(random_data)\n",
    "        preds = clf.predict(random_data)\n",
    "\n",
    "        det = np.array(synt_norm.index)[preds==-1]\n",
    "        ndet = np.array(synt_norm.index)[preds==1]\n",
    "\n",
    "\n",
    "        tp.extend([sum(np.in1d(det,pos))])\n",
    "        fp.extend([sum(np.in1d(det,neg))])\n",
    "        tn.extend([sum(np.in1d(ndet,neg))])\n",
    "        fn.extend([sum(np.in1d(ndet,pos))])\n",
    "\n",
    "pd.DataFrame(tp).to_csv(\"/Users/admin/Documents/CNV/article/figs/data_fig3/tp_amp.tsv\", sep=\"\\t\",index=False)\n",
    "pd.DataFrame(fp).to_csv(\"/Users/admin/Documents/CNV/article/figs/data_fig3/fp_amp.tsv\", sep=\"\\t\",index=False)\n",
    "pd.DataFrame(fn).to_csv(\"/Users/admin/Documents/CNV/article/figs/data_fig3/fn_amp.tsv\", sep=\"\\t\",index=False)\n",
    "pd.DataFrame(tn).to_csv(\"/Users/admin/Documents/CNV/article/figs/data_fig3/tn_amp.tsv\", sep=\"\\t\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synt_norm.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['17296', '17297', '17298', '17299', '17300', '17301', '17302',\n",
       "       '17303', '17304', '17307', '17321', '17323', '17325', '17330',\n",
       "       '17333', '17334', '17335', '17339', '17356', '17358', '17362',\n",
       "       '17363', '17366', '17373', '17377', '17381', '17383', '17384',\n",
       "       '17388', '17392', '17393', '17394', '17396'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def aberrantTargetsCapture(abSamples, normalSamples, reads_norm, conta=None, lower=-0.5, upper=0.5, verbose=True, output_path=False):\n",
    "    if conta == None:\n",
    "        conta = 1/reads_norm.shape[1]\n",
    "    f = pd.DataFrame(columns=[\"name\",\"loc\",\"amp\"])\n",
    "    \n",
    "    norm = np.mean(reads_norm[normalSamples], axis = 1)\n",
    "    reads_norm_norm = reads_norm/norm\n",
    "    \n",
    "    \n",
    "    q=0\n",
    "    for i in tqdm(reads_norm.columns):\n",
    "        x = reads_norm[i]/norm\n",
    "        x = np.array(np.log2(x[reads_norm[i]!=0]))\n",
    "        #pd.DataFrame(x).to_csv(\"/Users/admin/Documents/CNV/icr_res/\"+i+\".tsv\",sep=\"\\t\")\n",
    "        random_data = x.reshape(-1, 1)\n",
    "        clf = IsolationForest(contamination=conta).fit(random_data)\n",
    "        preds = clf.predict(random_data)\n",
    "\n",
    "        det = np.array(final_norm.index)[reads_norm[i]!=0][preds==-1]\n",
    "        ndet = np.array(final_norm.index)[reads_norm[i]!=0][preds==1]\n",
    "\n",
    "        for j in det:\n",
    "            amp = np.log2(reads_norm[i][j]/norm[j])\n",
    "            f.loc[q] = [i,j,amp]\n",
    "            if amp<lower:\n",
    "                f.loc[q] = [i,j,amp]\n",
    "                q=q+1\n",
    "            if amp>upper:\n",
    "                f.loc[q] = [i,j,amp]\n",
    "                q=q+1\n",
    "                \n",
    "    if verbose:\n",
    "        print(str(f.shape[0])+\" aberrant targets detected in \"+str(len(np.unique(f['name'])))+\" samples\")\n",
    "    return f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
