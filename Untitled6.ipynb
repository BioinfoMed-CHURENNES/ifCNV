{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "import subprocess\n",
    "import io\n",
    "import argparse\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "#               FUNCTIONS                 #\n",
    "###########################################\n",
    "\n",
    "\n",
    "def clean_reference(ref,outliers):\n",
    "    for i in outliers:\n",
    "        ref = ref.drop(labels=i,axis=1)\n",
    "\n",
    "    return ref\n",
    "\n",
    "def createReadsMatrix(pathToBam, bedFile, pathToBedtools, output=None, verbose=False):\n",
    "    cmd = [\"ls\", pathToBam]\n",
    "    res = subprocess.check_output(cmd)\n",
    "    final=pd.DataFrame()\n",
    "\n",
    "    for i in res.decode('utf-8').split(\"\\n\"):\n",
    "        if i.endswith(\".bam\"):\n",
    "            if verbose==True:\n",
    "                print(\"Processing sample \"+i[:-4]+\"...\")\n",
    "            command = [\n",
    "                pathToBedtools,\n",
    "                \"multicov\",\n",
    "                \"-bams\", pathToBam+\"/\"+i,\n",
    "                \"-bed\", bedFile]\n",
    "\n",
    "            res = subprocess.check_output(command)\n",
    "            data = io.StringIO(res.decode(\"utf-8\"))\n",
    "            df = pd.read_csv(data, sep='\\t',header=None)\n",
    "            nam = i[:-4]\n",
    "            final[nam] = df[len(df.columns)-1]\n",
    "            if verbose==True:\n",
    "                print(i[:-4]+\" Done\")\n",
    "    final.index = list(df[3])\n",
    "\n",
    "    if output is not None:\n",
    "        if verbose==True:\n",
    "            print(\"Reads matrix created !\")\n",
    "        final.to_csv(output,sep=\"\\t\")\n",
    "\n",
    "    return(final)\n",
    "\n",
    "\n",
    "def filterReads(reads,N,regtar=None,regsamp=None):\n",
    "    col = reads.columns\n",
    "    rows = reads.index\n",
    "    if regtar is not None:\n",
    "        reads = reads.filter(regex=regtar,axis=0)\n",
    "    if regsamp is not None:\n",
    "        reads = reads.filter(regex=\"^(?!\"+regsamp+\")\")\n",
    "    reads = reads.filter(regex=\"^(?!MSI)\",axis=0)\n",
    "    reads = reads.filter(regex=\"^(?!TN)\")\n",
    "    reads = reads.filter(regex=\"^(?!TP)\")\n",
    "    reads = reads.filter(regex=\"^(?!HD)\")\n",
    "    reads = reads.filter(regex=\"^(?!H2)\")\n",
    "    reads = reads.loc[reads.sum(axis=1)/len(reads.columns)>N,:]\n",
    "    filtered_samples = col[~np.in1d(col,reads.columns)]\n",
    "    filtered_targets = rows[~np.in1d(rows,reads.index)]\n",
    "    return(reads, filtered_samples, filtered_targets)\n",
    "\n",
    "\n",
    "def normalizeReads(reads):\n",
    "    reads_norm=reads/reads.sum(axis=0)\n",
    "    return(reads_norm)\n",
    "\n",
    "\n",
    "def aberrantSamples(reads,conta='auto'):    \n",
    "    tmp = np.percentile(reads, 99, axis = 0)/np.mean(reads, axis = 0)\n",
    "    random_data = np.array(tmp).reshape(-1,1)\n",
    "    clf = IsolationForest(contamination=conta).fit(random_data)\n",
    "    preds = clf.predict(random_data)\n",
    "    res_amp = np.array(reads.columns)[preds==-1]\n",
    "    \n",
    "    tmp = np.percentile(reads, 1, axis = 0)/np.mean(reads, axis = 0)\n",
    "    random_data = np.array(tmp).reshape(-1,1)\n",
    "    clf = IsolationForest(contamination=conta).fit(random_data)\n",
    "    preds = clf.predict(random_data)\n",
    "    res_del = np.array(reads.columns)[preds==-1]\n",
    "    \n",
    "    res = np.unique(np.concatenate((res_amp,res_del)))\n",
    "    norm = np.array(reads.columns[~np.in1d(reads.columns,res)])\n",
    "    \n",
    "    return(res, norm)\n",
    "\n",
    "\n",
    "\n",
    "def aberrantAmpliconsPerSample(name,reads_norm,CNVneg,conta=0.01):\n",
    "    random_data = np.array(reads_norm[name]).reshape(-1,1)\n",
    "    norm = np.array(np.mean(reads_norm[CNVneg], axis = 1))\n",
    "    clf = IsolationForest(contamination=conta).fit(norm.reshape(-1,1))\n",
    "    preds = clf.predict(random_data)\n",
    "    return(np.array(reads_norm.index)[preds==-1])\n",
    "\n",
    "#def aberrantAmpliconsPerSample(name,reads_norm,conta=0.01):\n",
    "#    random_data = np.array(reads_norm[name]).reshape(-1,1)\n",
    "#    clf = IsolationForest(contamination=conta).fit(np.array(np.mean(reads_norm, axis = 1)).reshape(-1,1))\n",
    "#    preds = clf.predict(random_data)\n",
    "#    return(np.array(reads_norm.index)[preds==-1])\n",
    "#\n",
    "\n",
    "def scoreAmplif(k,n,N):\n",
    "    p = n/N\n",
    "    x = np.log(1/((p**k)*(1-p)**(n-k)))*(k/n)\n",
    "    return x\n",
    "\n",
    "\n",
    "def amplifEvalGene(reads,abSamples,gene,sample):\n",
    "    reads_m = reads/reads.median(axis=0)\n",
    "    reads_m = reads_m.filter(regex=\"^\"+gene,axis=0)\n",
    "    sub = reads_m\n",
    "    for i in abSamples:\n",
    "        sub = sub.drop(labels=i,axis=1)\n",
    "    reads_m = reads_m[sample]\n",
    "    val = np.mean(reads_m)/np.mean(sub.mean())\n",
    "    if val==np.inf:\n",
    "        val = 100\n",
    "    return val\n",
    "\n",
    "\n",
    "def aberrantAmpliconsFinal(reads, reads_norm, CNVpos, CNVneg, scoreThreshold=20,conta=0.01,mode=\"fast\",run=\"ifCNV\"):\n",
    "    f = pd.DataFrame(columns=[\"Run\",\"Sample name\",\"Region\",\"Reads ratio\",\"Score\"])\n",
    "        \n",
    "    if mode==\"extensive\":\n",
    "        samples = [*CNVpos,*CNVneg]\n",
    "    if mode==\"fast\":\n",
    "        samples = CNVpos\n",
    "\n",
    "    q=0\n",
    "    for name in samples:       \n",
    "        abAmp = aberrantAmpliconsPerSample(name,reads_norm,CNVneg,conta=conta)\n",
    "        if abAmp.shape!=(0,):\n",
    "            genes = np.unique([i.split('_')[0] for i in abAmp])\n",
    "            for gene in genes:\n",
    "                r = re.compile(gene)\n",
    "                abEx = list(filter(r.match, abAmp))\n",
    "                exons1 = [i.split('_')[0]+\"_\"+i.split('_')[1] for i in abEx]\n",
    "                tmp = reads.filter(regex=\"^\"+gene,axis=0)\n",
    "                exons2 = [i.split('_')[0]+\"_\"+i.split('_')[1] for i in tmp.index]\n",
    "\n",
    "                score = scoreAmplif(len(abEx),tmp.shape[0],reads.shape[0])\n",
    "                amplif = amplifEvalGene(reads_norm, CNVneg, gene, name)\n",
    "\n",
    "                if score>scoreThreshold:\n",
    "                    f.loc[q] = [run,name,gene,amplif,score]\n",
    "                    q=q+1\n",
    "\n",
    "    return(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample C21D00896...\n",
      "C21D00896 Done\n",
      "Processing sample C21D00913...\n",
      "C21D00913 Done\n",
      "Processing sample C21D00920...\n",
      "C21D00920 Done\n",
      "Processing sample C21D00935...\n",
      "C21D00935 Done\n",
      "Processing sample D21D00857T...\n",
      "D21D00857T Done\n",
      "Processing sample D21D00873...\n",
      "D21D00873 Done\n",
      "Processing sample D21D00915T...\n",
      "D21D00915T Done\n",
      "Processing sample K21D00856...\n",
      "K21D00856 Done\n",
      "Processing sample K21D00951...\n",
      "K21D00951 Done\n",
      "Processing sample M21D00902...\n",
      "M21D00902 Done\n",
      "Processing sample M21D00905...\n",
      "M21D00905 Done\n",
      "Processing sample M21D00947...\n",
      "M21D00947 Done\n",
      "Processing sample N21D00884...\n",
      "N21D00884 Done\n",
      "Processing sample N21D00916...\n",
      "N21D00916 Done\n",
      "Processing sample N21D00939...\n",
      "N21D00939 Done\n",
      "Processing sample O21D00953...\n",
      "O21D00953 Done\n",
      "Processing sample P21D00880...\n",
      "P21D00880 Done\n",
      "Processing sample P21D00893M...\n",
      "P21D00893M Done\n",
      "Processing sample P21D00894...\n",
      "P21D00894 Done\n",
      "Processing sample P21D00901...\n",
      "P21D00901 Done\n",
      "Processing sample P21D00909...\n",
      "P21D00909 Done\n",
      "Processing sample P21D00910...\n",
      "P21D00910 Done\n",
      "Processing sample P21D00924...\n",
      "P21D00924 Done\n",
      "Processing sample P21D00925...\n",
      "P21D00925 Done\n",
      "Processing sample P21D00928M...\n",
      "P21D00928M Done\n",
      "Processing sample P21D00945...\n",
      "P21D00945 Done\n",
      "Processing sample P21D00954...\n",
      "P21D00954 Done\n",
      "Processing sample S21D00888...\n",
      "S21D00888 Done\n",
      "Processing sample TN01...\n",
      "TN01 Done\n",
      "Processing sample TN02...\n",
      "TN02 Done\n",
      "Processing sample TN03...\n",
      "TN03 Done\n",
      "Processing sample TN04...\n",
      "TN04 Done\n",
      "Processing sample TN05...\n",
      "TN05 Done\n",
      "Processing sample TN06...\n",
      "TN06 Done\n",
      "Processing sample TN07...\n",
      "TN07 Done\n",
      "Processing sample TN08...\n",
      "TN08 Done\n",
      "Processing sample TN09...\n",
      "TN09 Done\n",
      "Processing sample TN10...\n",
      "TN10 Done\n",
      "Processing sample TN11...\n",
      "TN11 Done\n",
      "Processing sample TN12...\n",
      "TN12 Done\n",
      "Processing sample TPHD728...\n",
      "TPHD728 Done\n",
      "Processing sample TPHD729...\n",
      "TPHD729 Done\n",
      "Processing sample TPHD730...\n",
      "TPHD730 Done\n",
      "Processing sample TPHD731...\n",
      "TPHD731 Done\n",
      "Processing sample X21D00872...\n",
      "X21D00872 Done\n",
      "Processing sample X21D00877...\n",
      "X21D00877 Done\n",
      "Processing sample X21D00887...\n",
      "X21D00887 Done\n",
      "Processing sample X21D00897...\n",
      "X21D00897 Done\n"
     ]
    }
   ],
   "source": [
    "pathBam = \"/Users/admin/Documents/tmp/bam_test_ifCNV/\"\n",
    "bed = \"/Users/admin/Documents/CNV/Panel_Juno_v3.bed\"\n",
    "bedtools = \"/Users/admin/miniconda3/bin/bedtools\"\n",
    "\n",
    "reads = createReadsMatrix(pathToBam=pathBam,bedFile=bed,pathToBedtools=bedtools,verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredReads, filteredS, filteredT = filterReads(reads, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "normReads = normalizeReads(filteredReads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNVpos, CNVneg = aberrantSamples(filteredReads,conta=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = aberrantAmpliconsFinal(filteredReads,normReads,CNVpos,CNVneg,mode=\"extensive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Sample name</th>\n",
       "      <th>Region</th>\n",
       "      <th>Reads ratio</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ifCNV</td>\n",
       "      <td>N21D00939</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>9.573497</td>\n",
       "      <td>117.482852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ifCNV</td>\n",
       "      <td>P21D00928M</td>\n",
       "      <td>MET</td>\n",
       "      <td>1.881284</td>\n",
       "      <td>21.073354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Run Sample name Region  Reads ratio       Score\n",
       "0  ifCNV   N21D00939   EGFR     9.573497  117.482852\n",
       "1  ifCNV  P21D00928M    MET     1.881284   21.073354"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"/Users/admin/Documents/tmp/test.txt\"\n",
    "final.to_csv(output, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
