{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-r RUN]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/admin/Library/Jupyter/runtime/kernel-ded14f25-2461-46e2-b892-e2e358060b54.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "#               FUNCTIONS                 #\n",
    "###########################################\n",
    "\n",
    "\n",
    "def clean_reference(ref,outliers):\n",
    "    for i in outliers:\n",
    "        ref = ref.drop(labels=i,axis=1)\n",
    "\n",
    "    return ref\n",
    "\n",
    "def createReadsMatrix(pathToBam, bedFile, pathToBedtools, output=None, verbose=False):\n",
    "    cmd = [\"ls\", pathToBam]\n",
    "    res = subprocess.check_output(cmd)\n",
    "    final=pd.DataFrame()\n",
    "\n",
    "    for i in res.decode('utf-8').split(\"\\n\"):\n",
    "        if i.endswith(\".bam\"):\n",
    "            if verbose==True:\n",
    "                print(\"Processing sample \"+i[:-4]+\"...\")\n",
    "            command = [\n",
    "                pathToBedtools,\n",
    "                \"multicov\",\n",
    "                \"-bams\", pathToBam+\"/\"+i,\n",
    "                \"-bed\", bedFile]\n",
    "\n",
    "            res = subprocess.check_output(command)\n",
    "            data = io.StringIO(res.decode(\"utf-8\"))\n",
    "            df = pd.read_csv(data, sep='\\t',header=None)\n",
    "            nam = i[:-4]\n",
    "            final[nam] = df[6]\n",
    "            if verbose==True:\n",
    "                print(i[:-4]+\" Done\")\n",
    "    final.index = list(df[3])\n",
    "\n",
    "    if output is not None:\n",
    "        if verbose==True:\n",
    "            print(\"Reads matrix created !\")\n",
    "        final.to_csv(output,sep=\"\\t\")\n",
    "\n",
    "    return(final)\n",
    "\n",
    "\n",
    "\n",
    "def filterReads(reads,N,regtar=None,regsamp=None):\n",
    "    if regtar is not None:\n",
    "        reads = reads.filter(regex=regtar,axis=0)\n",
    "    if regsamp is not None:\n",
    "        reads = reads.filter(regex=regsamp)\n",
    "    reads = reads.filter(regex=\"^(?!MSI)\",axis=0)\n",
    "    reads = reads.filter(regex=\"^(?!TN)\")\n",
    "    reads = reads.filter(regex=\"^(?!TP)\")\n",
    "    reads = reads.filter(regex=\"^(?!HD)\")\n",
    "    reads = reads.filter(regex=\"^(?!H2)\")\n",
    "    col = reads.columns\n",
    "    reads = reads.loc[:,reads.sum(axis=0)>N]\n",
    "    filtered_samples = col[~np.in1d(col,reads.columns)]\n",
    "    return(reads, filtered_samples)\n",
    "\n",
    "\n",
    "def normalizeReads(reads):\n",
    "    reads_norm=reads/reads.sum(axis=0)\n",
    "    return(reads_norm)\n",
    "\n",
    "\n",
    "def aberrantSamples(reads,conta='auto'):    \n",
    "    tmp = np.percentile(reads, 99, axis = 0)/np.mean(reads, axis = 0)\n",
    "    random_data = np.array(tmp).reshape(-1,1)\n",
    "    clf = IsolationForest(contamination=conta).fit(random_data)\n",
    "    preds = clf.predict(random_data)\n",
    "    res_amp = np.array(reads.columns)[preds==-1]\n",
    "    \n",
    "    tmp = np.percentile(reads, 1, axis = 0)/np.mean(reads, axis = 0)\n",
    "    random_data = np.array(tmp).reshape(-1,1)\n",
    "    clf = IsolationForest(contamination=conta).fit(random_data)\n",
    "    preds = clf.predict(random_data)\n",
    "    res_del = np.array(reads.columns)[preds==-1]\n",
    "    \n",
    "    res = np.unique(np.concatenate((res_amp,res_del)))\n",
    "    norm = reads.columns[~np.in1d(reads.columns,res)]\n",
    "    \n",
    "    return(res, norm)\n",
    "\n",
    "\n",
    "def aberrantAmpliconsPerSample(name,reads_norm,conta=\"auto\"):\n",
    "    random_data = np.array(reads_norm[name]).reshape(-1,1)\n",
    "    clf = IsolationForest(contamination=conta).fit(np.array(np.mean(reads_norm, axis = 1)).reshape(-1,1))\n",
    "    preds = clf.predict(random_data)\n",
    "    if verbose:\n",
    "        print(name)\n",
    "        print(np.array(reads_norm.index)[preds==-1])\n",
    "    return(np.array(reads_norm.index)[preds==-1])\n",
    "\n",
    "\n",
    "\n",
    "def amplifEvalGene(reads,abSamples,gene,sample):\n",
    "    reads_m = reads/reads.median(axis=0)\n",
    "    reads_m = reads_m.filter(regex=\"^\"+gene,axis=0)\n",
    "    sub = reads_m\n",
    "    for i in abSamples:\n",
    "        sub = sub.drop(labels=i,axis=1)\n",
    "    reads_m = reads_m[sample]\n",
    "    val = np.mean(reads_m)/np.mean(sub.mean())\n",
    "    if val==np.inf:\n",
    "        val = 100\n",
    "    return val\n",
    "\n",
    "\n",
    "def scoreAmplif(k,n,N,mu):\n",
    "    p = n/N\n",
    "    x = np.log(1/((p**k)*(1-p)**(n-k)))*(k/n)\n",
    "    return x\n",
    "\n",
    "def aberrantAmpliconsFinal(reads, reads_norm, abSamples,scoreThreshold,ampThreshold,mode=\"extensive\",run=\"ifCNV\"):\n",
    "    f = pd.DataFrame(columns=[\"run\",\"name\",\"gene\",\"ratio\",\"score\"])\n",
    "    \n",
    "    #if mode==\"extensive\":\n",
    "        #samples = abSamples[]\n",
    "\n",
    "    q=0\n",
    "    for name in samples:\n",
    "        abAmp = aberrantAmpliconsPerSample(name,reads_norm)\n",
    "        if abAmp.shape!=(0,):\n",
    "            genes = np.unique([i.split('_')[0] for i in abAmp])\n",
    "            for gene in genes:\n",
    "                r = re.compile(gene)\n",
    "                abEx = list(filter(r.match, abAmp))\n",
    "                exons1 = [i.split('_')[0]+\"_\"+i.split('_')[1] for i in abEx]\n",
    "                tmp = reads.filter(regex=\"^\"+gene,axis=0)\n",
    "                exons2 = [i.split('_')[0]+\"_\"+i.split('_')[1] for i in tmp.index]\n",
    "\n",
    "                score = scoreAmplif(len(abEx),tmp.shape[0],reads.shape[0],len(abEx)/tmp.shape[0])\n",
    "\n",
    "                amplif = amplifEvalGene(reads_norm, abSamples, gene, name)\n",
    "\n",
    "                if score>scoreThreshold and amplif>ampThreshold:\n",
    "                    f.loc[q] = [run,name,gene,amplif,score]\n",
    "                    q=q+1\n",
    "\n",
    "\n",
    "    return(f)\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "#               MAIN                      #\n",
    "###########################################\n",
    "parser = argparse.ArgumentParser(description='ifCNV')\n",
    "parser.add_argument('-i', '--input', type=str, help='Path to the input bam folder')\n",
    "parser.add_argument('-b', '--bed', type=str, help='Path to the bed file')\n",
    "parser.add_argument('-t', '--bedtools', type=str, help='Path to bedtools')\n",
    "parser.add_argument('-m', '--mode', type=str, default='fast' help='fast or extensive')\n",
    "parser.add_argument('-cs', '--contaSamples', default = \"auto\", help='Contamination parameter for the AberrantSamples function')\n",
    "parser.add_argument('-ct', '--contaTargets', default = \"auto\", help='Contamination parameter for the AberrantTargets function')\n",
    "parser.add_argument('-sT', '--scoreThreshold', type=int, default=5, help='Threshold on the localisation score')\n",
    "parser.add_argument('-aT', '--ampThreshold', type=float, default=1.2, help='Threshold on the amplification ratio')\n",
    "parser.add_argument('-rS', '--regSample', type=str, help='A pattern ')\n",
    "parser.add_argument('-i', '--input', type=str, help='Path to the input bam folder')\n",
    "parser.add_argument('-i', '--input', type=str, help='Path to the input bam folder')\n",
    "parser.add_argument('-v', '--verbose', type=str, help='A boolean, default ')\n",
    "args = parser.parse_args()\n",
    "\n",
    "PATH = \"/mnt/Bioinfo/BioTS/Results//ADIVaR/FDG_Juno_v3/\"\n",
    "output_path = \"/mnt/chu-ngs/Labos/BioTS/SOMAT/DIAG/Juno/MET_amp/\"\n",
    "correspondance = pd.read_csv(\"/mnt/Bioinfo/BioTS/Projets/CNV/correspondance.txt\",sep=\"\\t\")\n",
    "run = args.run\n",
    "\n",
    "if run is None:\n",
    "   print(\"-r has no default value\")\n",
    "   ld = []\n",
    "else:\n",
    "   ld = os.listdir(PATH)\n",
    "   ld = np.array(ld)[np.array([bool(re.findall(run,ld[i])) for i in range(len(ld))])]\n",
    "\n",
    "N = 1536 #number of amplicons\n",
    "\n",
    "res = pd.DataFrame(columns=[\"run\",\"name\",\"gene\",\"ratio\",\"score\"])\n",
    "k = 0\n",
    "\n",
    "if len(ld)>0:\n",
    "    path = PATH+ld[0]+'/data/'\n",
    "    reads = openJson(path,N)\n",
    "    reads = sumLibraries(reads)\n",
    "    reads = correctIndex(reads,correspondance)\n",
    "    final, filtered_samples = filterReads(reads,N*200,output_path=output_path+\"reads_\"+args.run+\".tsv\")\n",
    "    q=0\n",
    "    #filtered_samples = filtered_samples[[bool(re.search(\"^P\", i)) for i in filtered_samples]]\n",
    "    if len(filtered_samples)>0:\n",
    "        for i in filtered_samples:\n",
    "            tmp = [run,i,\"-\",\"Non Analysable\",\"-\"]\n",
    "            res.loc[q] = tmp\n",
    "            q=q+1\n",
    "    final_norm = normalizeReads(final)\n",
    "    abSamples = aberrantSamples(final)\n",
    "    #allSamples = final.filter(regex=\"^P\").columns\n",
    "\n",
    "    ff = aberrantAmpliconsFinal(final,final_norm,abSamples,final.columns,run,1)\n",
    "    if ff.shape[0]>0:\n",
    "        res = res.append(ff)\n",
    "\n",
    "    #res = res.loc[np.in1d(res[\"gene\"],\"MET\"),:]\n",
    "    res.index=range(res.shape[0])\n",
    "    #negSamples = allSamples[~np.in1d(allSamples,res[\"name\"])]\n",
    "    #q = res.shape[0]\n",
    "    #if len(negSamples)>0:\n",
    "    #    for i in negSamples:\n",
    "    #        q=q+1\n",
    "    #        res.loc[q] = [run,i,\"MET\",\"Negatif\",\"-\"]\n",
    "\n",
    "    res.to_csv(output_path+\"CNV_Juno_all_\"+run+\".tsv\", sep=\"\\t\",index=False)\n",
    "\n",
    "else:\n",
    "    print(\"Erreur. Verifier le nom du run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
