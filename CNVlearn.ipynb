{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "###########################################\n",
    "#               FUNCTIONS                 #\n",
    "###########################################\n",
    "\n",
    "\n",
    "def clean_reference(ref,outliers):\n",
    "    for i in outliers:\n",
    "        ref = ref.drop(labels=i,axis=1)\n",
    "\n",
    "    return ref\n",
    "\n",
    "def norm_ref(ref):\n",
    "    med = ref.median(axis=0)\n",
    "    norm_ref = ref/med\n",
    "    return norm_ref, med\n",
    "\n",
    "def create_synthetic(norm_ref,med,N):\n",
    "    synt = pd.DataFrame(index=norm_ref.index,columns=range(N))\n",
    "    for j in range(N):\n",
    "        for i in norm_ref.index:\n",
    "            synt[j][i] = np.random.choice(norm_ref.loc[norm_ref.index==i].values.flatten())\n",
    "\n",
    "        synt[j] = synt[j] * np.random.choice(med)\n",
    "    synt.columns = [\"sample_\" + str(i) for i in range(synt.shape[1])]\n",
    "    return synt\n",
    "\n",
    "def add_features(synt,sample,gene,factor,exon=None):\n",
    "    if exon is None:\n",
    "        pattern = gene\n",
    "        tmp = [str(synt.index[i]).split(\"_\")[0] for i in range(synt.shape[0])]\n",
    "        synt.loc[[tmp[i]==pattern for i in range(len(tmp))],sample] = synt.loc[[tmp[i]==pattern for i in range(len(tmp))]][sample] * factor\n",
    "        \n",
    "    if exon is not None:\n",
    "        pattern = gene + \"_\" + exon\n",
    "        tmp = [str(synt.index[i]).split(\"_\")[0] + \"_\" + str(synt.index[i]).split(\"_\")[1] for i in range(synt.shape[0])] \n",
    "        synt.loc[[tmp[i]==pattern for i in range(len(tmp))],sample] = synt.loc[[tmp[i]==pattern for i in range(len(tmp))]][sample] * factor\n",
    "    \n",
    "    res = synt\n",
    "    return res\n",
    "\n",
    "\n",
    "def openJson(path,n):\n",
    "    \"\"\"\n",
    "    Opens json files in path to create a reads matrix\n",
    "    \"\"\"\n",
    "    tmp = os.listdir(path)\n",
    "    tmp = np.array(tmp)[np.array([bool(re.findall(\"depths.json$\",tmp[i])) for i in range(len(tmp))])]\n",
    "    reads = np.zeros((n,len(tmp)))\n",
    "    amplicons = [\"\" for x in range(n)]\n",
    "    q=0\n",
    "    for p in tmp:\n",
    "        with open(path+p) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            for i in range(n):\n",
    "                amplicons[i] = data[i]['name']\n",
    "                for j in data[i]['depths']:\n",
    "                    reads[i,q] = int(data[i]['depths'][j]['min'])\n",
    "        q=q+1\n",
    "    reads = pd.DataFrame(data = reads,index=amplicons)\n",
    "    reads.columns = [i.split('_')[0]+'_'+i.split('_')[1] for i in tmp]\n",
    "    return reads\n",
    "\n",
    "def sumLibraries(reads):\n",
    "    samples = np.unique([i.split('_')[0] for i in reads.columns])\n",
    "    reads_f = np.zeros((reads.shape[0],len(samples)))\n",
    "    q=0\n",
    "    for i in samples:\n",
    "        sub = reads.filter(regex=\"^\"+i)\n",
    "        reads_f[:,q] = sub.sum(axis=1)\n",
    "        q=q+1\n",
    "    reads_f = pd.DataFrame(data = reads_f,index=reads.index)\n",
    "    reads_f.columns = list(samples)\n",
    "    return(reads_f)\n",
    "\n",
    "def correctIndex(reads,correspondance):\n",
    "    l = [\"\" for x in range(len(reads.index))]\n",
    "    q=0\n",
    "    for i in reads.index:\n",
    "        l[q] = i[(len(i)-9):len(i)]\n",
    "        q=q+1\n",
    "    final = reads[[correspondance[\"amplicon\"][0] in l[x] for x in range(len(l))]]\n",
    "    for i in correspondance[\"amplicon\"]:\n",
    "        if i!=correspondance[\"amplicon\"][0]:\n",
    "            final = pd.concat([final,reads[[i in l[x] for x in range(len(l))]]])\n",
    "    final.index = correspondance[\"gene_exon\"] + \"_\" + correspondance[\"amplicon\"]\n",
    "    return final\n",
    "\n",
    "\n",
    "def filterReads(reads,N,output_path):\n",
    "    reads = reads.loc[:,reads.sum(axis=0)>N]\n",
    "    reads = reads.filter(regex=\"^(?!MSI)\",axis=0)\n",
    "    reads = reads.filter(regex=\"^(?!TN)\")\n",
    "    reads = reads.filter(regex=\"^(?!TP)\")\n",
    "    reads = reads.filter(regex=\"^(?!HD)\")\n",
    "    reads = reads.filter(regex=\"^(?!H2)\")\n",
    "    reads.to_csv(output_path, sep=\"\\t\",index=True)\n",
    "    return(reads)\n",
    "\n",
    "\n",
    "def normalizeReads(reads,output_path,save=False):\n",
    "    reads_norm=reads/reads.median(axis=0)\n",
    "    reads = np.log(reads+1)\n",
    "    if save==True:\n",
    "        reads_norm.to_csv(output_path, sep=\"\\t\",index=True)\n",
    "    return(reads_norm)\n",
    "\n",
    "\n",
    "def aberrantSamples(reads,conta='auto'):\n",
    "    read = reads.astype(\"float\")\n",
    "    tmp = np.percentile(reads, 99, axis = 0)/np.mean(reads, axis = 0)\n",
    "    random_data = np.array(tmp).reshape(-1,1)\n",
    "\n",
    "    clf = IsolationForest(contamination=conta).fit(random_data)\n",
    "    preds = clf.predict(random_data)\n",
    "    res = np.array(reads.columns)[preds==-1]\n",
    "    return(res)\n",
    "\n",
    "def aberrantSamples2(reads):\n",
    "    read = reads.astype(\"float\")\n",
    "    tmp = np.percentile(reads, 5, axis = 0)/np.mean(reads, axis = 0)\n",
    "    random_data = np.array(tmp).reshape(-1,1)\n",
    "\n",
    "    clf = IsolationForest(contamination=0.1).fit(random_data)\n",
    "    preds = clf.predict(random_data)\n",
    "    res = np.array(reads.columns)[preds==-1]\n",
    "    return(res)\n",
    "\n",
    "\n",
    "def aberrantAmplicons(reads_norm,abSamples):\n",
    "    for name in res:\n",
    "        random_data = np.array(reads_norm[name]).reshape(-1,1)\n",
    "        clf = IsolationForest(contamination=0.001).fit(np.array(np.mean(reads_norm, axis = 1)).reshape(-1,1))\n",
    "        preds = clf.predict(random_data)\n",
    "        print(name)\n",
    "        print(np.array(reads_norm.index)[preds==-1])\n",
    "\n",
    "def aberrantAmpliconsPerSample(name,reads_norm,conta='auto',verbose=False):\n",
    "    random_data = np.array(reads_norm[name]).reshape(-1,1)\n",
    "    clf = IsolationForest(contamination=conta).fit(np.array(np.mean(reads_norm, axis = 1)).reshape(-1,1))\n",
    "    preds = clf.predict(random_data)\n",
    "    if verbose:\n",
    "        print(name)\n",
    "        print(np.array(reads_norm.index)[preds==-1])\n",
    "    return(np.array(reads_norm.index)[preds==-1])\n",
    "\n",
    "\n",
    "def aberrantAmpliconsPerSample2(name,reads,abSamples,verbose=False):\n",
    "    ab = [i in abSamples for i in reads.columns]\n",
    "    normalReads = reads[np.delete(reads.columns,ab)]\n",
    "    med = np.percentile(normalReads, 99, axis = 1)\n",
    "    reads = (reads.T/med).T\n",
    "    random_data = np.array(reads[name]).reshape(-1,1)\n",
    "    clf = IsolationForest(contamination=0.05).fit(np.array(np.median(reads, axis = 1)).reshape(-1,1))\n",
    "    preds = clf.predict(random_data)\n",
    "    if verbose:\n",
    "        print(name)\n",
    "        print(np.array(reads.index)[preds==-1])\n",
    "    return(np.array(reads.index)[preds==-1])\n",
    "\n",
    "\n",
    "\n",
    "def percentagePerExon(amplified,reads,verbose=False):\n",
    "    genes = [i.split('_')[0] for i in reads.index]\n",
    "    exons = [i.split('_')[1] for i in reads.index]\n",
    "    g_e = [genes[i]+'_'+exons[i] for i in range(len(genes))]\n",
    "    n_ge = np.array([g_e.count(i) for i in np.unique(g_e)])\n",
    "    ag = [i.split('_')[0] for i in amplified]\n",
    "    ae = [i.split('_')[1] for i in amplified]\n",
    "    age = [ag[i]+'_'+ae[i] for i in range(len(amplified))]\n",
    "    f = pd.DataFrame(index=np.unique(age),columns=[\"percentage\"])\n",
    "    f = f.fillna(0)\n",
    "    for i in range(len(np.unique(age))):\n",
    "        f['percentage'][i] = 100*float(age.count(''.join(np.unique(age)[i]))/n_ge[np.unique(g_e)==''.join(np.unique(age)[i])])\n",
    "        if verbose:\n",
    "            if f['percentage'][i]>50:\n",
    "                print(np.unique(age)[i] + \": \" + str(round(f['percentage'][i]))+'%'+' des amplicons de l\\'exon sont aberrants')\n",
    "    return(f)\n",
    "\n",
    "def percentagePerGene(amplified,reads,verbose=False):\n",
    "    genes = [i.split('_')[0] for i in reads.index]\n",
    "    ag = [i.split('_')[0] for i in amplified]\n",
    "    n_g = np.array([genes.count(i) for i in np.unique(genes)])\n",
    "    f = pd.DataFrame(index=np.unique(ag),columns=[\"percentage\"])\n",
    "    f = f.fillna(0)\n",
    "    for i in range(len(np.unique(ag))):\n",
    "        f['percentage'][i] = 100*float(ag.count(''.join(np.unique(ag)[i]))/n_g[np.unique(genes)==''.join(np.unique(ag)[i])])\n",
    "        if verbose:\n",
    "            if f['percentage'][i]>50:\n",
    "                print(np.unique(ag)[i] + \": \" + str(round(f['percentage'][i]))+'%'+' des amplicons du gene sont aberrants')\n",
    "    return(f)\n",
    "\n",
    "def amplifEvalGene(reads,abSamples,gene,sample):\n",
    "    reads_m = reads/reads.median(axis=0)\n",
    "    sub = reads_m\n",
    "    for i in abSamples:\n",
    "        sub = sub.drop(labels=i,axis=1)\n",
    "    reads_m = reads_m.filter(regex=\"^\"+gene,axis=0)\n",
    "    reads_m = reads_m[sample]   \n",
    "    val = np.mean(reads_m)/np.mean(sub.mean())\n",
    "    if val==np.inf:\n",
    "        val = 100\n",
    "    return val\n",
    "\n",
    "def scoreAmplif(k,n,N):\n",
    "    p = n/N\n",
    "    x = np.log(1/((p**k)*(1-p)**(n-k)))*(k/n)\n",
    "    # score = 1/(1+np.exp(-x))\n",
    "    score = x/390 + 190/390\n",
    "    \n",
    "    return x\n",
    "\n",
    "def aberrantAmpliconsFinal(reads, reads_norm, abSamples,abSamples2,run,threshold):\n",
    "    f = pd.DataFrame(columns=[\"run\",\"name\",\"gene\",\"amplif\",\"score\"])\n",
    "        \n",
    "    q=0 \n",
    "    for name in abSamples2:\n",
    "        #abAmp = aberrantAmpliconsPerSample2(name,reads_norm,abSamples,verbose=False)\n",
    "        abAmp = aberrantAmpliconsPerSample(name,reads_norm,verbose=False)\n",
    "        if abAmp.shape!=(0,):\n",
    "            genes = np.unique([i.split('_')[0] for i in abAmp])\n",
    "            for gene in genes:\n",
    "                r = re.compile(gene)\n",
    "                abEx = list(filter(r.match, abAmp))\n",
    "                exons1 = [i.split('_')[0]+\"_\"+i.split('_')[1] for i in abEx]\n",
    "                tmp = reads.filter(regex=\"^\"+gene,axis=0)\n",
    "                exons2 = [i.split('_')[0]+\"_\"+i.split('_')[1] for i in tmp.index]\n",
    "                \n",
    "                score = scoreAmplif(len(abEx),tmp.shape[0],reads.shape[0])\n",
    "                \n",
    "                amplif = amplifEvalGene(reads, abSamples, gene, name)\n",
    "\n",
    "                if score>threshold:\n",
    "                    if amplif>1:\n",
    "                        f.loc[q] = [run,name,gene,amplif,score]\n",
    "                        q=q+1\n",
    "                    #if amplif<1:\n",
    "                    #    f.loc[q] = [run,name,gene,amplif,score]\n",
    "                    #    q=q+1\n",
    "\n",
    "    return(f)\n",
    "\n",
    "\n",
    "def aberrantAmpliconsFinal2(reads, reads_norm, abSamples,abSamples2,run,threshold):\n",
    "    f = pd.DataFrame(columns=[\"run\",\"name\",\"gene\",\"amplif\",\"score\"])\n",
    "        \n",
    "    q=0 \n",
    "    for name in abSamples2:\n",
    "        #abAmp = aberrantAmpliconsPerSample2(name,reads_norm,abSamples,verbose=False)\n",
    "        abAmp = aberrantAmpliconsPerSample(name,reads_norm,verbose=False)\n",
    "        if abAmp.shape!=(0,):\n",
    "            genes = abAmp\n",
    "            for gene in genes:\n",
    "                r = re.compile(gene)\n",
    "                abEx = list(filter(r.match, abAmp))\n",
    "                #print(abEx)\n",
    "                tmp = reads.filter(regex=\"^\"+gene,axis=0)                \n",
    "                score = scoreAmplif(len(abEx),tmp.shape[0],reads.shape[0])\n",
    "                \n",
    "                amplif = amplifEvalGene(reads, abSamples, gene, name)\n",
    "\n",
    "                if score>threshold:\n",
    "                    if amplif>1:\n",
    "                        f.loc[q] = [run,name,gene,amplif,score]\n",
    "                        q=q+1\n",
    "                    #if amplif<1:\n",
    "                    #    f.loc[q] = [run,name,gene,amplif,score]\n",
    "                    #    q=q+1\n",
    "\n",
    "    return(f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "    pd.DataFrame(tpp).to_csv(\"/Users/admin/Documents/CNV/article/tp_del_\"+str(p)+\".tsv\", sep=\"\\t\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8148772eaa47d3815aac402ebc6cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#synt[synt==0] = 0.000000001\n",
    "\n",
    "tpp=[]\n",
    "q=[]\n",
    "r=[]\n",
    "s=[]\n",
    "for p in tqdm(range(1,101)):\n",
    "    for k in (range(1,round(synt.shape[0]/2),5)): \n",
    "        for factor in range(0,15):\n",
    "            factor = factor/10\n",
    "            synt = pd.read_csv(\"/Users/admin/Documents/CNV/synthetic_raw.tsv\",sep=\"\\t\",index_col=0)\n",
    "\n",
    "            col = \"sample_\"+str(np.random.randint(32))\n",
    "            row = synt.index[np.random.randint(synt.shape[0],size=k)]\n",
    "\n",
    "            neg = synt.columns[~np.in1d(synt.columns,col)]\n",
    "\n",
    "            for i in row:\n",
    "                synt.at[i,col] = synt.at[i,col]*factor\n",
    "\n",
    "            synt_norm = synt/synt.median(axis=0)\n",
    "            #synt_norm = np.log(synt_norm)\n",
    "            pos = col\n",
    "\n",
    "            tmp = np.percentile(synt, 1, axis = 0)/np.mean(synt, axis = 0)\n",
    "            random_data = np.array(tmp).reshape(-1,1)\n",
    "\n",
    "            clf = IsolationForest(contamination=\"auto\").fit(random_data)\n",
    "            preds = clf.predict(random_data)\n",
    "            det = np.array(synt.columns)[preds==-1]\n",
    "\n",
    "            ndet = synt.columns[~np.in1d(synt.columns,det)]\n",
    "            #random_data = np.array(tmp).reshape(-1,1)\n",
    "            #clf = IsolationForest(contamination=\"auto\").fit(np.array(np.mean(synt_norm[normal], axis = 1)).reshape(-1,1))\n",
    "            #preds = clf.predict(random_data)\n",
    "\n",
    "            #det = np.array(synt_norm.index)[preds==-1]\n",
    "            #ndet = synt.index[~np.in1d(synt.index,det)]\n",
    "            #pos = row\n",
    "            #neg = synt.index[~np.in1d(synt.index,pos)]\n",
    "\n",
    "            tpp.extend([sum(np.in1d(det,pos))])\n",
    "\n",
    "\n",
    "pd.DataFrame(tpp).to_csv(\"/Users/admin/Documents/CNV/article/tp_del_\"+str(p)+\".tsv\", sep=\"\\t\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be4a0e891194df0bf96b63dfcdef2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=51.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "gene_ex = pd.read_csv(\"/Users/admin/Documents/CNV/article/gene_ex.tsv\",sep=\"\\t\")\n",
    "factor = 3\n",
    "N = 1475\n",
    "sc=[]\n",
    "ex=[]\n",
    "le=[]\n",
    "\n",
    "gg = np.unique([i.split('_')[0] for i in gene_ex[\"ex\"]])\n",
    "exon = 'none'\n",
    "\n",
    "for i in tqdm(gg):\n",
    "    synt = pd.read_csv(\"/Users/admin/Documents/CNV/synthetic_raw.tsv\",sep=\"\\t\",index_col=0)\n",
    "\n",
    "    col = \"sample_\"+str(np.random.randint(32))\n",
    "    reads = add_features(synt,sample=col,gene = i,factor = factor)\n",
    "    \n",
    "    synt_norm = reads/reads.median(axis=0)\n",
    "    \n",
    "    normal = synt.columns[~np.in1d(synt.columns,col)]\n",
    "\n",
    "    random_data = np.array(synt_norm[col]/np.array(np.mean(synt_norm[normal], axis = 1))).reshape(-1, 1)\n",
    "    clf = IsolationForest(contamination=1/32).fit(random_data)\n",
    "    preds = clf.predict(random_data)\n",
    "\n",
    "    det = np.array(synt_norm.index)[preds==-1]\n",
    "    ndet = np.array(synt_norm.index)[preds==1]\n",
    "    \n",
    "    \n",
    "    if exon=='none':\n",
    "        genes = np.unique([i.split('_')[0] for i in det])\n",
    "        le.extend([len(genes)])\n",
    "\n",
    "        for i in genes:\n",
    "            r = re.compile(i)\n",
    "            abEx = list(filter(r.match, det))\n",
    "\n",
    "            tmp = reads.filter(regex=\"^\"+i,axis=0)                \n",
    "            score = scoreAmplif(len(abEx),tmp.shape[0],1475)\n",
    "            sc.extend([score])\n",
    "            ex.extend([i])\n",
    "            \n",
    "    if exon!='none':\n",
    "        exons = np.unique([i.split('_')[0]+\"_\"+i.split('_')[1] for i in det])\n",
    "        le.extend([len(exons)])\n",
    "        for i in exons:\n",
    "            r = re.compile(i)\n",
    "            abEx = list(filter(r.match, det))\n",
    "\n",
    "            tmp = reads.filter(regex=\"^\"+i,axis=0)                \n",
    "            score = scoreAmplif(len(abEx),tmp.shape[0],1475)\n",
    "            sc.extend([score])\n",
    "            ex.extend([i])\n",
    "            \n",
    "\n",
    "pd.DataFrame(sc).to_csv(\"/Users/admin/Documents/CNV/article/scores_gene_3.tsv\", sep=\"\\t\",index=False)\n",
    "pd.DataFrame(ex).to_csv(\"/Users/admin/Documents/CNV/article/cibles_gene_3.tsv\", sep=\"\\t\",index=False)\n",
    "pd.DataFrame(le).to_csv(\"/Users/admin/Documents/CNV/article/nombre_gene_3.tsv\", sep=\"\\t\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AKT1', 'ALK', 'BRAF', 'BRCA1', 'BRCA2', 'CDKN2A', 'CTNNB1',\n",
       "       'DDR2', 'EGFR', 'ERBB2', 'ERBB4', 'FGFR2', 'FGFR3', 'FOXL2',\n",
       "       'GNA11', 'GNAQ', 'GNAS', 'H3F3A', 'HIST1H3B', 'HRAS', 'IDH1',\n",
       "       'IDH2', 'JAK1', 'JAK3', 'KIT', 'KRAS', 'MAP2K1', 'MAP2K2', 'MAPK1',\n",
       "       'MAPK3', 'MET', 'MITF', 'NF1', 'NOTCH1', 'NRAS', 'PALB2', 'PDGFRA',\n",
       "       'PIK3CA', 'PTEN', 'RAD51C', 'RAD51D', 'RB1', 'RET', 'RICTOR',\n",
       "       'ROS1', 'SMAD4', 'STK11', 'TERT', 'TP53', 'TYRP1', 'VHL'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for b in tqdm(range(10)):\n",
    "    tp=[]\n",
    "    fp=[]\n",
    "    fn=[]\n",
    "    tn=[]\n",
    "    for k in tqdm(range(1,15)):\n",
    "        #print(k)\n",
    "        synt = pd.read_csv(\"/home/scabello/Documents/run_juno/CNV/synthetic_raw.tsv\",sep=\"\\t\",index_col=0)\n",
    "        reads = add_features(synt,sample=\"sample_0\",gene = gene,factor = factor)\n",
    "        temp = [\"sample_0\"]\n",
    "\n",
    "        tmp = np.percentile(reads, 99, axis = 0)/np.mean(reads, axis = 0)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.plot(tmp)\n",
    "\n",
    "        for N in np.random.randint(30,size=k):\n",
    "            reads = add_features(reads,sample=\"sample_\"+str(N+1),gene = gene,factor = factor)\n",
    "            temp.extend([\"sample_\"+str(N+1)])\n",
    "\n",
    "        neg = np.array(ref)[np.in1d(ref,temp)==False]\n",
    "        \n",
    "        #print(temp)\n",
    "        p=[]\n",
    "        q=[]\n",
    "        r=[]\n",
    "        s=[]\n",
    "        tmp = np.percentile(reads, 99, axis = 0)/np.mean(reads, axis = 0)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.plot(tmp)\n",
    "\n",
    "        for N in (range(20)):\n",
    "            tmp = np.percentile(reads, 99, axis = 0)/np.mean(reads, axis = 0)\n",
    "            random_data = np.array(tmp).reshape(-1,1)\n",
    "            #plt.xticks(rotation=90)\n",
    "            #plt.plot(tmp)\n",
    "            clf = IsolationForest(contamination=0.1).fit(random_data)\n",
    "            preds = clf.predict(random_data)\n",
    "            abSamples = pd.DataFrame(reads.columns)[preds==-1]\n",
    "            ndet = np.array(ref)[np.in1d(ref,abSamples)==False]\n",
    "            #print(abSamples)\n",
    "            p.extend([sum(np.in1d(abSamples,temp))])\n",
    "            q.extend([sum(np.in1d(abSamples,neg))])\n",
    "            r.extend([sum(np.in1d(ndet,temp))])\n",
    "            s.extend([sum(np.in1d(ndet,neg))])\n",
    "\n",
    "        tp.extend([np.mean(p)])\n",
    "        fp.extend([np.mean(q)])\n",
    "        fn.extend([np.mean(r)])\n",
    "        tn.extend([np.mean(s)])\n",
    "\n",
    "\n",
    "    pd.DataFrame(tp).to_csv(\"/home/scabello/Documents/run_juno/CNV/article/conta/tp_\"+gene+\"_\"+str(factor)+\"_samples_\"+str(b)+\".tsv\", sep=\"\\t\",index=False)\n",
    "    pd.DataFrame(fp).to_csv(\"/home/scabello/Documents/run_juno/CNV/article/conta/fp_\"+gene+\"_\"+str(factor)+\"_samples_\"+str(b)+\".tsv\", sep=\"\\t\",index=False)\n",
    "    pd.DataFrame(fn).to_csv(\"/home/scabello/Documents/run_juno/CNV/article/conta/fn_\"+gene+\"_\"+str(factor)+\"_samples_\"+str(b)+\".tsv\", sep=\"\\t\",index=False)\n",
    "    pd.DataFrame(tn).to_csv(\"/home/scabello/Documents/run_juno/CNV/article/conta/tn_\"+gene+\"_\"+str(factor)+\"_samples_\"+str(b)+\".tsv\", sep=\"\\t\",index=False)\n",
    "\n",
    "\n",
    "    #print(str(k)+\": \"+str(q/100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
